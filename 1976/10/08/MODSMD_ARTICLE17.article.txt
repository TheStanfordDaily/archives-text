# Collegiate testing validity questioned
## 
### Carlin Chrisman 
Every year the future of nearly
2.5 million students relies on the
results of tests administered by
the Educational Testing Service
(ETS). As a Stanford student,
you had to take the SAT in order
to be admitted, and most other
American colleges also require
the SAT.
Yet the ETS, which also ad
ministers the Achievement
Tests. Advanced Placement
Tests, the Law School Achieve
ment Test, has recently been the
subject of serious questioning
concerning the reliability and
validity of these tests and their
over-emphasis in admissions
depa rtments.
SATs, for example, have a
high degree of variability. Wil
liam Artjoff, Director of the Gol

lege Board Program Division,
says "if a typical group of candi
dates were to take the SAT a sec
ond time, say a day after the first
time, 1/3 would get scores 45
points higher or lower than the
day before."
The ETS has taken into ac
count the imprecision of its tests
and now rounds off its scores to
the nearest 10, so that two stu
dents scoring 586 and 589 on a
test would both receive a 590.
Even a difference as large as 72
points on the math test and 66
points on the verbal test is con
sidered by ETS to be "so insig
nificant that it can't be taken
seriously.
Yet, although a 60 point differ
ence is "statistically meaning
less," Stephen Brill reports in an
October '74 issue of the New

Yorker magazine that ten com
mittee members at six prestigi
ous universities said that a 60
point difference would be a
major factor in determining ad
mission.
The reliability of a test can be
measured in terms of a reliability
coefficient, which expresses the
degree to which two measure
ments of ability for the same
group of people agree and are
consistent.
An ETS pamphlet indicates
that the reliability coefficient for
their tests is "more than
adequate for the purposes for
which they are intended." And
critics generally agree that ETS
tests are the most reliable tests
available, according to Brill. Yet
ETS advises that each test score
be considered within a range

of figures, the size of the range
depending on the particular test.
Thus it is very unfair for admis
sions to reject a student on the
basis of a 60 point difference.
Placing heavy emphasis on a
student's test scores is one of the
abuses of the testing service. ETS
discourages this practice,
suggesting that admissions
committees, "evaluate other in
dicators of the student's ability
. . . such as rank in class, grade
point average, recommenda
tions. school and community ac
tivities, motivation, and evi
dence of creative ability."
Yet many admissions depart
ments don't have the manpower
necessary to read and evaluate
all these indicators. Brill states
"most colleges devote minimal
manpower and money to select

ing candidates and rely heavily
on test scores and other statis
tics." Bowdoin College, which
has eliminated College Board
examinations, employs seven
fulltime professionals to read
and evaluate 3700 applications.
Ceorgetown Law School, by con
trast, has only two admissions
officers for its 7000 applica
tions.
The validity ot the test scores
— how well they predict a stu
dent's ability to do first-year
work — is also being questioned.
ETS tests are generally regarded
as having the highest quotient of
predictive validity. Yet test ex
pert Lawrence Plotkin believes,
reports Brill, that their predic
tive validity is very low. in fact,
"almost meaningless."
