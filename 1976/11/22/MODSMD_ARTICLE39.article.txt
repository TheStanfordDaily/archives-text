# Questionnaire, interviews probe faculty views of Honor Code
## 
### 
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
In their charge letter to the Student Conduct Legislative
Council (SCLC), President Richard W. Lyman and the ASSU
Council of Presidents explicitly recognized that an adequate
evaluation of Stanford's Honor Code must not focus solely
on students.
The attitudes, behavior, and perceptions of the faculty are
at least equally important: Do they support the current
system in theory? Do they support it in practice? Under what
circumstances do faculty proctor examinations? What does
an instructor do when he or she suspects a student of cheat
ing? If the Honor Code procedures are not followed, why
not? Do faculty members view student cheating as a serious
problem at Stanford?
To answer these and related questions, the SCLC under
took two surveys of faculty members during late spring 1976.
First, a questionnaire was mailed to a random sample of 200
faculty in the Schools of Humanities and Sciences, Engineer
ing, and Earth Sciences. Several weeks later, a subsample of
50 faculty in H & S was interviewed on Honor Code topics
not covered by the short-answer questionnaire. This report
will present our findings from these two data collection
efforts, beginning with the questionnaire survey.
The tables below show the proportional representation,
by rank and by school, of the faculty population from which
our sample was selected. The percentages in the second and
third columns allow comparisons between the total popula
tion, those faculty who were mailed questionnaires, and our
respondent group of 83. It is clear that our respondents are
reasonably representative, on the characteristics of rank and
school affiliation, of the population from which they were
selected.
The response rate, uncorrected for faculty in our sample
who were on leave spring quarter, is about 42%. We know of
20 faculty members who were on leave, whose questionnaires
were returned by their offices, and the real number on leave
is certainly somewhat higher. Correcting by the conservative
estimate of 20 yields a quite respectable 46% response rate.
School % of % %
population sampled questionnaire
respondents
Earth Sciences 5% 6% 5%
Engineering 23% 17% 23%
H & S: Sciences & Math 22% 26% 22%
H & S: Humanities 30% 26% 24%
H & S: Social Sciences 20% 25% 26%
N = 640 200 83
Professor 56% 56% 55%
Associate Professor 16% 20% 18%
Assistant Professor 24% 20% 23%
Other 4% 3% 5%
N= 640 200 83
Overview of Questionnaire Responses
Our respondents are not very well informed about the
contents of Stanford's Honor Code, even about those aspects
of the Code relating to faculty. Asked quiz-fashion if the
Honor Code prohibits exam proctoring, 47% of our sample
correctly responded that it does; 35% responded incorrectly,
and 18% selected the "Don't Know" option.
Another question asked if faculty conduct is regulated by
the Honor Code: 43% are aware tnat faculty conduct is
regulated, 35% incorrectly believe that it is not, and 22%
responded "Don't Know."
Not surprisingly, most faculty also lack detailed know
ledge of the functioning of the Honor Code System: for
example, the statement "The typical punishment for honor
violations is six month's suspension" is false (one quarter or
three months is typical)—3o% checked that the statement is
false, 7% thought it was true, and 63% checked "Don't
Know."
Perhaps discouraged by their quiz performance, a later
question finds most of our sample describing themselves as
"not well informed about the obligations of the Honor
Code" (31%), or "somewhat informed" (60%); a mere 9%
consider themselves to be "well informed."
Asked how they learned about the Honor Code, the
predominant information sources indicated are official publi
cations (49%), Blue Book statements (47%), and general
word-of-mouth (40%).
Attitudes Toward The Honor Code
Our sample is quite divided in response to the question,
"How committed are you to Stanford's Honor Code?"
Forty-two percent are either uncaring or opposed, and 58%
align themselves on the positive side, the extremes, "I believe
in it very strongly" and"I feel it should be abolished" are
virtually equal (15% and 16% respectively).
Asked to assess the general awareness among students and
faculty of the existence of the Honor Code, our sample
agrees that "most" or "many" on campus have this level of
knowledge; their perception of student and faculty know
ledge of Honor Code requirements, however, is much less
optimistic—especially with respect to other faculty. Twenty
percent think "most" of their faculty colleaaues know about

its requirements compared with 80% thinking "most" are
aware of its existence.
It is interesting that our sample perceives more faculty
supporting the Honor Code by their behavior than faculty
who favor Honor Code continuation. As we also discovered
during the interviews, a noticable number of Stanford faculty
observe Honor Code requirements in practice, but wish the
system were different.
Few faculty, 8%, believe that "the current level of aca
demic dishonesty at Stanford poses a very serious threat to
the academic process;" the rest of the sample splits about
evenly between the 45% who believe the threat is moder
ately serious," and the 47% who believe it is "not very
serious."
Asked to indicate their agreement with a battery of opin
ion statements about the Honor Code, our sample ranges on
every item from "agree strongly" to "disagree strongly," with
no clear consensus on any item. The statements included:
"The interpretation of the Honor Code is too vague and
indefinite;" "The Honor Code lacks strong faculty support,"
and "Punishments for honor violations are too lenient." (One
possible example of consensus is the last of the six items,
"Honor Code infractions occur because of ignorance of its
contents," which evokes 65% disagreeing mildly or strongly,
9% agreeing mildly or strongly, and 26% on the fence.)
Behavior in Cheating Situations
The remainder of the questionnaire focuses on the person
al behavior and experiences of the faculty with respect to
issues of academic dishonesty.
We first inquired about some teaching practices which we
believed might reduce the likelihood of cheating. We again
found wide variability on most items; for example, a third of
our respondents never check blue books for signatures, and
the four categories ranging from "rarely" to "always each
contain 12% to 19% of the remaining respondents.
Similarly with respect to changing exam or assignment
practices to reduce the likelihood of cheating, each category
from "never" to "always" has 14% to 25% of the sample. On
these items, as well as many others, one cannot describe
"faculty behavior" beyond indicating that it varies widely
plater we will reexamine our data for disciplinary differ
ences).
A majority of our sample (55%) "never" informs students
of the contents of the Honor Code, although 58% frequently
or always indicate their own boundaries of acceptable be
havior with respect to class assignments. Seventy-four percent
do not -ever proctor exams or arrange for proctoring; 15% do
so "rarely" or "sometimes," and 12% "frequently" or "al
ways."
Our sample was asked, "In the past three years, how
many times have you had reason to suspect your students of
cheating?" The responses: never 37%; once 14%; a few times
40%; several times 8%; many times 1%.
Those with some recent experience (i.e., who did not
check "never") were asked to indicate what actions they
took with respect to the most recent incident and also with
respect to the most serious incident. As the two columns
below show, the actions taken in the two circumstances
aren't very different—perhaps for many the most recent inci
dent was also the most serious, a possibility we neglected to
inquire about.
"In the most recent (most serious) instance of suspected
cheating in the past 3 years, what action did you take?"
% checked "yes"
Most Most
Recent Serious
No action 16% 5%
Discussed the situation with colleagues 51 42
Sought proof or support for your
suspicions 42 36
Discussed the situation with the
student(s) involved 49 49
Penalized the student(s) involved 23 33
Sought advice from the dean of student
affairs or other administrator 7 15
Followed Honor Code procedures and
referred the problem to the
President's Office 4 5
Other 5 5
Those who did not follow Honor Code procedures were
asked why not: of eight options, the two most frequently
checked were "sufficient evidence to convince others is too
difficult to obtain" (33%), and"I was in the best position to
evaluate infractions and impose appropriate penalties" (25%).
Sixteen percent allowed that they didn't know what the
Honor Code requirements were.
A hypothetical case was put to the whole sample, regard
less of their personal experience: "If you had reasonable
evidence that an undergraduate student had copied from
another student during an exam, what would you do 7" The
hypothetical actions differ substantially from the self-re
ported real actions: 42% would "follow Honor Code pro
cedures and refer '~ie problem to the President's Office,"

compared with the 5% who did so with respect to the most
serious cheating incident encountered recently.
We can speculate about this contrast, but we cannot
account for it. The hypothetical situation in the question
naire was deliberately made unambiguous, while real life is
often quite ambiguous—this may account for some of the
shift. Also the questionnaire probably had the effect of
raising the level of awareness concerning the Honor Code,
and may have also intentions to abide by its requirements.
A question asking about the relative desirability of the
Honor Code versus examination proctoring produced res
ponses very similar to the earlier question about Honor Code
commitment: 58% strongly or moderately prefer the Honor
Code, 20% don't care, and 22% strongly or moderately prefer
proctoring. Here, however, the extreme categories are very
different: 40% pro Honor Code versus 14% pro proctoring.
Asked why the Honor Code was preferred, 80% checked
"Better student-faculty relationships." Also checked by over
half our sample: "The Code reinforces individual honesty and
responsibility" (68%), "More effective in promoting hon
esty" (61%), and "More freedom in designing class assign
ments" (54%).
Those preferring proctoring had their say, too, almost
unanimously citing as a reason for their preference that
"Proctoring ensures fair and equal treatment for all students"
(94%); over half also checked that "The Honor Code is not
observed in practice" (53%).
Most of our sample (51%) declined to speculate about
whether "the current incidence of academic dishonesty at
Stanford is higher now than was true in the past:" those with
opinions were more likely to believe it has increased (31%)
than that it has not (19%).
Student-Faculty Comparisons
The first two-and-one-half pages of the faculty question
naire consist of questions repeated from a survey of 350
graduate and undergraduate students earlier in spring quarter.
We will now consider some of the ways in which students and
faculty agree and disagree about Honor Code issues.
Comparing students and faculty on our quiz about Honor
Code contents, we find their performances are equally bad,
faculty are less likely to say "Don't know," but not much
more likely to be right.
For example, "The Honor Code prohibits exam proc
toring:" 47% of the faculty and 42% of the students in our
sample know this is true. The faculty are slightly more aware
than students that the Honor Code regulates their behavior:
43% of the faculty, 32% of the undergraduates, and 27% of
the graduates responded correctly to this item. Clearly, any
educational program recommended by the SCLC needs to be
addressed to faculty as well as to students.
The three most common information sources used by
faculty for Honor Code questions are the same as the three
most used by students—official publications, used more by
faculty than students; Blue Books, less so for faculty than
students; and general word-of-mouth, checked by about 40%
each.
Faculty are slightly more likely to think themselves
"somewhat informed" about the contents of the Honor Code
(60% faculty, 52% undergraduates, 46% graduates), and less
likely to think themselves "not well informed" (31% faculty,
35% undergraduates, 44% graduates). The differences, how
ever, are not large.
Graduate students and faculty respond similarly to the
question "How strongly committed are you to Stanford's
Honor Code," showing themselves less committed than un
dergraduates:
Faculty Grad. Undergrad
% % %
J believe in it very strongly. 15 14 20
I think it is a good idea. 43 48 51
I don't care one way or the other. 16 15 16
I feel it should be altered. * 10 13 11
I feel it should be abolished. 16 10 2
Asked about perceptions of students with respect to Hon
or Code knowledge and support (e.g., "Do you think that
Stanford students know that Stanford has an Honor Code 7"),
undergraduates and faculty agree quite closely, and graduate
students hold less favorable perceptions-the latter are prob
ably generalizing their own relative lack of knowledge and
enthusiasm. Asked similarly for perceptions of faculty, we
find that students hold substantially more favorable views of
the faculty than do our faculty respondents of their collea
gues.
For example
"Do you think that your faculty (colleagues! know about its
requirements?"
Faculty Grad. Undergrad.
% % %
Most 20 51 58
Many 40 29 27
Some 34 15 14
Few 7 5 2
The exception to this pattern is that all respondents agree
on the extent to which faculty support the Honor Code by
their behavior; our faculty respondents here hold more favor
able perceptions of their colleagues.
Respondents indicated the extent of their agreement with
a battery of opinion statements about the Honor Code.
Student and faculty opinions are similar on most items, the
exceptions being those shown below.
Th« Honor Code lacks strong faculty support
Faculty Grad. Undergrad.
% % %
Agree strongly 5 12 8
Agree mildly 29 21 27
Not sure 24 37 41
Disayee mildly 35 26 20
Disagree strongly 7 4 4
Punishments for honor violations are too lenient
Faculty Grad. Undergrad.
% % %
Agree strongly 9 10 4
Agree mildly 27 12 11
Not sure 51 62 67
mildly 12 13 13
Disagree strongly 1 4 5
(The latter table should not be taken too seriously since we
already know that the vast majority of our samples is un
aware of what the typical punishment is.)
The last question asked of both samples is: "Do you
believe that the current level of academic dishonesty at
Stanford poses a serious threat to the academic process?"
Faculty are slightly more likely to believe the threat is
"moderately serious:"
Faculty Grad. Undergrad.
% % %
Very serious 8 11 11
Moderately serious 45 36 32
Not very serious 47 51 55
In summary, we find no striking differences between
student and faculty responses to questions asked of both
groups Those differences that do appear show faculty to be
more aware of a cheating problem, less committed to an
unchanged Honor Code, and generally viewing their collea
gues as less informed and supportive. To repeat, these differ
ences are modest.
Disciplinary Differences among Faculty
Our analyses show nume r ous differences among our res
pondents related to academic discipline (departments are
grouped into Engineering, H & S Humanities, Sciences and
Math, and Social Sciences). The differences are often quite
large, unfortunately, they are also often inconsistent and
puzzling.
If we wait until it all "makes sense," however, this report
will never get written; instead, we'll just report our findings
and point out the various interpretive difficulties as they
arise. The number of cases on which percentages are based is
shown in tables by N I); the Ns are often small-the reade
should completely disregard any differences less than 10%,
and treat with caution differences between 10% and 20%.
With respect to knowledge of Honor Code contents, social
science faculty are considerably more likely to answer cor
rectly. For example, here are the two questions specifically
concerning faculty:
Eng'g. Hum. Sci. Soc. Sci.
"The Honor Code
prohibits exam
proctoring." % "True" 41 42 57 60
(17) (19) (18) (20)
"The Honor Code
does not regulate
faculty conduct." % "False" 41 39 39 60
Curiously, the social science faculty are the least likely to
think themselves "well informed about the obligations of the
Honor Code "
% "well informed"
Eng'g. Hum. Sci. Soc. Sci.
24 10 ' 6 0
% "not well informed
18 32 28 40
N= (17) (19) (18) (20)
The different disciplines seem to use different informa
tion sources for Honor Code matters/The engineers predomi
nantly use official documents and Blue Books; the humani
t.es faculty, newspaper articles and Blue Books; the social
scientists use faculty colleagues, and the science faculty use a
little bit of everything.
Asked about the strength of their commitment to Stan
ford's Honor Code, we again see differences

Eng'g. h.im. Sci. Soc. Sci
Believe strongly 18i 11 22 6
59 /50 72 56
Good Idea 41 39 50 50
Don't care 18 17 11 22
Alter it 6 17 0 17
Abolis 24 34 17 23
Abolish it 18 17 17 6
N- 117) (18) (18) (18)
The strong support from the sciences faculty, and relative
lack of support from those in humanities is surprising, especi
ally in light of the student survey results showing cheating,
concern about cheating, and support for proctoring to be
high among students planning to go to professional school
and low among those with graduate school intentions. To
equate the former students with science majors and the latter
with humanities majors, is to overstate the case; but still,
student and faculty data here fail to support each other as
strongly as they might.
On two sets of questions soliciting faculty perceptions of
Honor Code knowledge and support among colleagues and
students, we find engineering faculty consistently holding
more favorable views than other respondents; social science
faculty consistently hold unfavorable views, frequently with
the agreement of humanities faculty. Here are several ex
amples:
"Do you think that Stanford students know the Honor Code
requirements?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 56 18 50 20
N= (16) (17) (18) (20)
"Do you think that Stanford students favor continuation of
the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 44 41 44 24
N= (16) (17) (16) (17;
"Do you think that your faculty colleagues favor
continuation of the Honor Code?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 47 24 22 7
N= (17) (17) (18) (15)
"Do you think that your faculty colleagues support it (the
Honor Code) by their behavior?"
Eng'g. Hum. Sci. Soc. Sci.
% "Most" 62 44 33 21
N= (16) (16) (18) (19)
We then asked for a global assessment of the seriousness
of the threat posed by the current level of academic dis
honesty; we again find the engineers quite optimistic and
everyone else less so
Eng'g. Hum. Sci. Soc. Sci.
Not very serious 62% 39% 39% 42%
Moderately serious 38 50 57 47
Very Serious 0 11 6 11
N= (16) (18) (18) (19)
A set of opinion statements referring to the Honor Code
again finds engineering and social science faculty (joined by
science faculty) at opposite poles, as shown in the typical
distributions below.
"The interpretation of the Honor Code is too vague and
indefinite."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 29 12 0 5
N = (17) (16) (16) (19)
"The Honor Code covers too many areas of conduct. .
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 41 18 0 10
N= (17) (17) (16) (19)
"The Honor Code lacks strong faculty support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 18 6 0 5
% Agree strongly 18 33 47 45
N = (17) (18) (17) (20)
"The Honor Code lacks strong student support."
Eng'g. Hum. Sci. Soc. Sci.
% Disagree strongly 12 11 0 0
% Agree strongly 35 34 56 50
N = (17) (18) (18) (20)
Of six questions about recent teaching practices, only one
shows disciplinary differences. "Reviewing your recent teach

ing practices at Stanford, do you generally proctor exams, or
arrange for proctoring by others?"
Eng'g. Hum. Sci. Soc. Sci.
% "Never" 82 67 82 65
(17) (18) (17) (20)
The relative frequency of proctoring reported by
humanities faculty, ana infrequency reported by science
faculty is somewhat surprising.
Faculty were asked to report on both their most recent
and most serious cases of student cheating. Our population
for these questions is reduced to 54, subtracting the 20 who
have not had occasion to suspect any cheating during the past
three years. Percentage comparisons between disciplines are
consequently less reliable, and only large differences deserve
our attention.
Social science faculty are the most likely to discuss a
probable cheating problem with faculty colleagues (62% and
56%, most recent case and most serious case, respectively);
engineering faculty are the least likely to have discussed their
most recent experience (40%), and humanities faculty to
have discussed their most serious case (29%).
Social science faculty are also conspicuously more likely to
seek proof or support for their suspicions: 62% did so
vis-a-vis their most recent experience, compared with 20% of
the engineering faculty. Social science faculty are simply
more likely to have responded to their experiences with
action of one sort or another; in addition to the activities
mentioned above, they are also somewhat more likely to
discuss the situation with the student(s) involved (over 60%,
compared with 36-60% of their colleagues).
Few responded by following Hono r Code
procedures—between 0 and 14%. Asked why they didn't
follow Honor Code procedures, engineering faculty ter.dad to
reply "I was in the best position to evaluate infractions and
impose appropriate penalties" (50%); humanities and science
faculty selected the response "Sufficient evidence to
convince others is too difficult to obtain" (31% each); and
social science respondents chose several options—
"I didn't know what the requirements were" — 27%
"The official procedures are too time-consuming" — 33%
"Sufficient evidence. . .is too difficult to obtain" — 47%
"I, or others I know, used disciplinary channels before and
was disappointed with the results" — 27%
Asked hypothetically what they would do if they had
"reasonable evidence that an undergraduate student had
copied from another student during an exam," our sample in
general indicates a higher level of activity with respect to all
options.
Disciplinary differences appear: 50% of the science faculty
would discuss the situation with colleagues, versus 21% in
humanities; 47% of the humanities faculty indicated that
they would penalize the student, compared with 6% of the
science faculty; 44% of the science faculty would seek advice
from administrators, versus 12% of the engineering faculty;
31% of the humanities faculty would "follow Honor Code
procedures," compared with the other extreme of 53% of
engineering faculty.
A question asking about the relative desirability of the
Honor Code versus proctoring for the conduct of exams
yields a few surprises:
Eng'g. Hum. Sci. Soc. Sci.
% % % %
Strongly prefer Honor Code 65 37 39 21
(in between) 12 10 28 21
No preference 18 26 0 37
(in between) 6 10 11 5
Strongly prefer proctoring 0 16 22 16
N = (17) (19) (18) (19)
Responses from engineering and humanities are consistent
with earlier responses; it is a surprise to see the split among
science faculty—no one on the fence and 33%, the largest
among the four groups, on the proctoring side. Similarly,
earlier responses from social science faculty do not anticipate
the luke-warm response to proctoring that we see above.
Those preferring the Honor Code were asked for their
reasons; again our base for percentages is reduced, and we
show below the ranked preferences indicated by 25% or more
of the faculty in each of the four disciplinary areas.
Reasons for preferring the Rank of reason (1 = Highest), if
Honor Code over proctoring checked by 25% or more of faculty
for the conduct of exams: in a discipline:
Eng'g. Hum. Sci. Soc. Sci.
More effective in promoting
honesty 1* 1 3
Less work for instructor 5* 6
Better student-faculty
relationships 1* 2 1 2
More freedom in designing
class assignments 3* 4 4 1
Especially desirable for the
types of courses I teach 4 5* 5* 3
The Code reinforces individual
honesty & responsibility 2 3* 2
The Code educates in community
responsibility 3* 3* 5*
N= (16) (14) (12) (15)
* = tied rank
Again the social science faculty are distinct from our other
respondents; they indicate tar fewer reasons ( in part because
a lower percentage favor the Honor Code in the first place),
and their first-ranked reason differs from the two preferred
by others in its emphasis on instructors and teaching ease
rather than student-faculty relations or student honesty.
Faculty preferring proctoring also responded to a list of
possible reasons; the group is too small, however, to make
worthwhile disciplinary comparisons.
We're at somewhat of a loss to summarize just what has
been clarified by this investigation of discipline-related
differences among our faculty respondents.
The consistency with which we find engineering faculty at
one pole and social scientists at the other, often with 20-30
percentage points or more between them, strongly suggests
that the difference-whatever its source—is real and deserves
attention. While the other two groups, science faculty and
humanities faculty, frequently shift their relative positions,
they are far more likely to align themselves close to the social
science faculty than close to the engineering faculty.
This means that, among our respondents at least, the
relatively negative viewpoint predominates on Honor Code
topics; as to who espouses it, we can be very sure the group
includes social science faculty, and equally sure that it does
not include engineering faculty—and that's about the limit of
our predictive ability.
Rank Difference among Faculty
Differences among our respondents that relate to their
academic rank are neither as frequent nor as large as those
just examined for discipline. They do exist, however, and
generally support the hypothesis that new members of an
organization (in our case, assistant professors) will be less
supportive of its traditions and less likely to perceive
widespread commitment and loyalty in the population at
large. (Again, Ns are shown in tables to remind the reader
that the number of cases may be quite small.)
There are no differences by rank among our sample on
their quiz performance, though a separate question finds
assistant professors less likely to think themselves "well
informed about the obligations of the Honor Code"—o%,
compared with 10% of the professors; % "not well informed"
is 42% of the assistant professors and 26% of the professors.
Information sources differ somewhat, professors favoring
official publications (54%) and Blue Books (50%), and
assistant professors indicating faculty colleagues and
"handling cheating cases" over other options.
Asked about the strength of their commitment to the
Honor Code, our respondents said:
Ass't. Assoc.
Profs. Profs. Profs.
I believe in it strongly. 0% 33% 15%
I think it is a good idea. 42 33 44
I don't care one way or the
other. 26 8 15
I feel it should be altered. 16*8 5
I feel it should be abolished. 10 8 20
N = (19) (12) (39)
Two questions seeking perceptions of student support for
the Honor Code produce somewhat contradictory results. In
response to the statement "The Honor Code lacks strong
student support" we find among those agreeing strongly or
mildly, 41% of the professors and 58% of the assistant
professors.
Vet another statement, "Most students support the Honor
Code by their behavior," the difference is reversed-42% of
the assistant professors agree, and only 31-33% of the associ
ate professors and professors agree. These differences are not
large, of course; it is also worth remembering that of 14
opinion statements, only these two show differences at all.
The global perception question. "Do you believe that the
current level of academic dishonesty at Stanford poses a
serious threat to the academic process," finds professors least
likely to say "not very serious," and assistant professors most
likely to say "Yes, very serious."
Ass't. Assoc.
Profs. Profs. Profs.
Not very serious 53% 50% 41%
Moderately serious 32 42 49
Very serious 16 0 5
N = (19) (12) (39)
In response to a set of questions about their recent
teaching practices, we find professors least likely to always
"indicate (their) own boundaries of acceptable behavior with

respect to class assignments" (13% versus 32% of the assistant
professors), and more likely to check Blue Book signatures
"always" (26% versus 10% of the assistant professors).
Assistant professors are conspicuous for their interest in
seeking colleague advice "always or frequently" when cheat
ing is suspected-37% versus 1 7% of the professors; they are
also more likely to proctor exams or arrange for proctoring
by others.
» Ass't.
Profs. Profs.
% "always" or
"frequently" proctor 21 13
% "never" proctor 53 74
N = (19) (39)
The following table summarizes our sample's recent ex
perience with cheating.
"In the past three years, how many times have you had
reason to suspect your students of cheating?"
Ass't. Assoc.
Profs. Profs. Profs.
Never 16% 33% 54%
Once 37 8 5
A few times 42 50 33
Several times 0 8 8
Many times 5 0 0
N = (19) (12) (39)
Subsequent questions were addressed to those who indi
cated recent experience, percentages calculated on the small
er population—which yields too few associate professors to
consider separately. The tables below show the behaviors
reported by assistant professors and professors.
Ass't.
Profs. Profs.
Most recent instance:
No action 18% 12%
Discussed the situation
with colleagues 76 38
Sought proof or support for
your suspicions 76 29
Discussed situation with
student involved 70 33
Penalized student(s)
• involved 35 17
Sought advice from Dean
of Student Affairs or
other administrator 12 8
Followed Honor Code procedures
8< referred the problem to
President's Office 6 4
N = (16) (18)
Ass't.
Profs. Profs.
Most serious instance:
No action 6% 4%
Discussed situation with
colleagues 65 25
Sought proof or support
for your suspicions 65 21
Discussed situation with
student involved 70 29
Penalized student(s)
involved 53 17
Sought advice from dean of student
affairs or other administrator 24 17
Followed Honor Code procedures
and referred problem to
the President's Office 6 8
N = (16) (17)
Although it is clear that assistant professors report a wider
range of actions, the ranks of the most popular actions are
very similar for both groups.
There are no differences in response to the question of
why Honor Code procedures were not followed: only two
explanations were chosen frequently, and chosen about
equally for all ranks—"Sufficient evidence to convince others
is too difficult to obtain," and"I was in the best position to
evaluate infractions and impose appropriate penalties."
The hypothetical cheating problem addressed to all res
pondents shows no differences not seen earlier; as noted
before, the percent who would follow Honor Code proce
dures increases substantially:
Ass't. Assoc.
Profs. Profs. Profs.
% would follow Honor Code
procedures 53% 42% 46%
N= (19) (12) (39)
Assistant professors turn out to be evenly divided on the
question of preferred system for the conduct of exams.
Honor Code or procto. ng.

Ass't. Assoc.
Profs. Profs. Profs.
% strongly prefer Honor Code 21% 42% 46%
% strongly prefer proctoring 21 17 13
N = (19) (12) (39)
Assistant professors are somewhat more likely than others
in our sample to have been at an Honor Code school prior to
arriving at Stanford-42%, compared with 33% of the associ
ate professors and 21% of the professors. Over half of the
assistant professors with prior experience believe that the
level of cheating is higher at Stanford, while less than half of
the professors hold that view.
Interview Findings and Conclusion
As the reader may recall, a subsample of 50 faculty
members in H & S was interviewed on Honor Code topics not
covered in the questionnaire. Although our conclusions must
be tentative, due to the small sample size, we can use inter
view responses to help round out our picture of the faculty
presented in the preceding pages.
The first area of questioning stemmed from our gradual
realization that faculty members have no single definition of
what constitutes proctoring an examination. Perhaps they are
right to be confused, for no official document defines the
term; on the other hand, they are expressly prohibited, by
Honor Code requirements, from being present during exams.
Our question on this topic was "If an instructor or TA
stays in the room during an exam, is that proctoring, in your
opinion?"
Yes 19%
No 60
Depends upon instructor's N=so
reasons 21
The vast majority of our interview sample rejects a single
definition of proctoring, commenting that an instructor who
stays in the room expresses his intent by his behavior, which
is usually interpreted correctly by students. Extreme ex
amples would be the instructor who marches up and down
the aisles looking at students' work, and the instructor who
turns his back to the class and reads a book.
So what happens during exams? "Do you or a TA usually
stay in the room during exams?"
Ass't.
Prof. Prof.
No 14% 67%
Yes 64 13
"Only a few minutes to
answer questions 21 20
N= (14 (15)
The above difference is large and worth noting, even with
a small sample. Most of those who do not stay in the room
volunteered the comment that the Honor Code prohibits
their staying; conversely, those who do stay do not consider
their behavior to be in violation of Honor Code requirements.
That the assistant professors above who are oresent during
exams do, in fact, assume the honesty of their students is
strongly implied in their responses to the question, "Are
students allowed to do their exams somewhere else—in a
library, for example?"
Ass't.
Prof. Prof.
Yes 83% 54%
No 17 46
N = (12) (13)
We asked several questions about teaching and assignment
practices: which, if any, are deliberately designed to reduce
opportunities for academic dishonesty?; which, if any, re
quire assuming the honesty of students?; the educational
value of the latter practices—e.g., what would be lost in
educational terms were these practices discarded for alterna
tives less dependent upon student honesty?
All we learned from this set of questions is that most of
our sample do not think in these terms. A few respondents
said that they try not to present students with strong tempta
tions, take-home closed-book exams, for instance; on the
other hand, no one seems to find this type of exam educa
tionally indispensable.
In short, the faculty members we interviewed have teach
ing practices with which they are comfortable, both in educa
tional terms and with respect to assumptions of student
honesty; and these practices (which are, of course, extremely
diverse) have not been significantly influenced by considera
tions of honesty or dishonesty.
We got an interesting range of responses to tvw questions
soliciting suggestions for what students and faculty might do
"to foster academic honesty and minimize the incidence of
Honor Code infractions. The questions were open-ended, in
part to encourage discussion and in part because we were
unable to predict probable responses.
We develop* codes after the interviews; the dimension
we selecttd for coding faculty suggestions for faculty action
is especially interesting and unexpected Our respondents
offered suggestions like "Don't tempt students too much,"
"Inform students about Honor Code requirements," "Check
Blue Book signatures and talk to students who refuse to
sign," and "Don't be lazy—design different make-up exams
and different exams for different sections." Responses like
these we labeled "mechanical," a sort of oil-the-machine
and-keep-a-close-eye-on-it approach.
Other faculty members gave quite different suggestions:
"Let students know that you are serious both about your
work and about theirs," "Give lots of written feedback on
papers so students really believe that their work gets your
serious attention," "Grab your students intellectually; cut
out the chicken-shit courses," and "Discourage student
competitiveness; allow and encourage cooperation, group
projects, etc." These responses we labeled "pedagogic"—the
attitude that dishonesty among students is not an Honor
Code problem, but rather a teacher's problem.
Many in our sample made multiple suggestions for their
faculty colleagues, but no one offered both mechanical and
pedagogic suggestions To reduce Stanford faculty to two
types, on almost any dimension, would be a gross oversimpli
fication; the difference we see here is distinct, and even
dramatic, but a longer interview and/or a larger sample would
certainly reveal subtleties and gradations that we've missed.
It is still interesting to speculate about the "pure cases" at
the extremes they don't seem to see the same world. To one
group, academic dishonesty is essentially the students' prob
lem; they, the faculty, will help them to be honest by
reminding them of their obligations and removing large rocks
they see on the path, but it is really up to the students. The

other group scarcely mentions students, so interested are
they in the educational setting in which they see dishonesty
thriving. To them, the teacher who sees widespread cheating
should examine his teaching first, and later worry about the
students' ethical training.
Without presuming to judge "who's right" on the subject,
we think Stanford is fortunate to have both viewpoints
represented on its faculty. Their respective numbers are esti
mated in the following table.
Faculty Action: Ass't.
Prof. Prof.
% %
No suggestions 7 40
Mechanical suggestions 61 45
Pedagogic suggestions 33 15
N= (18) (20)
The question inviting suggestions for student action was
less fruitful. Many had none (33%); the most frequent sugges
tion was that students observe the reporting requirement of
the Honor Code (40%), but this was almost invariably follow
ed by parenthetical comments like "but of course they
won't," and "you wouldn't be doing this study if students
were willing to report themselves and others." No other
suggestion presented included as many as 10% of our sample.
The final pair of questions asks the faculty to consider the
SCLC's judgmental oroblem: "Suppose we find from our
student survey that 10% of present Stanford undergraduates
have cheated on exams, in one way or another, since arriving
here. Would you change your own teaching practices in
response to this finding? Would you be in favor of Honor
Code modifications in view of this finding?"
The responses are "No"—strongly negative to the first
question (87%), and predominantly negative to the second
(55%; 34% "Yes," the rest unsure). Among those who would
not change their own practices is 15% who found the ques
tion inappropriate because their current practices do not rely

upon the Honor Code. (Twenty-eight percent of the assistant
professors made this comment, and 10% of the professors.) It
is too bad. but not surprising, that our sample provides so
little guidance in this tricky area.
The two faculty surveys reported on in these pages were,
in our view, worthwhile undertakings. Most importantly, our
results confirm among the faculty sample a level of ignoiance
about Honor Code matters similar to that found in the
student survey. Though ignorant, however, they are not ter
ribly unhappy. Some consistent disciplinary differences ap
peared, but they are not large enough to justify labeling one
or more fields as "Honor Code disaster areas."
Our respondents hold a range of opinions about the
Honor Code and its characteristics, positive and negative, but
it is important to note the scant evidence that these opinions
influence their behavior—either with respect to general teach
ing practices or to the handling of cheating by students.
Our sample claims to support the Honor Code by their
behavior, and also perceives that most faculty do so—yet
their own reports of their behavior fail, in general, to confirm
their assertion. The report on the student survey concludes
that the Honor Code system is not seen to be working, even
though individual student honesty is at a fairly high level.
Widespread student rejection of the obligation to report
others accounts in part for the low visibility of the system.
We must also conclude, however, that the faculty, in
general, contributes to this situation by their behavioral indif
ference. Most are not hostile to the system; indeed there is
considerable enthusiasm expressed for the Honor Code versus
exam proctoring.
This support is apparently not perceived by students, nor
is faculty observance of the Honor Code—to the extent that
it is being observed—recognized as such. Faculty behavior,
like individual student honesty, seems to be largely independ
ent of the Honor Code system. This does not imply that the
system is unnecessary, but rather that awareness of it must be
raised before the SCLC can adequately address other issues
related to the system's effectiveness.
