# Building an artificial brain: physics prof says he can think it out
## 
### Jiri Weiss 
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
"To heck with the real brain
I am more interested in
whether we can make an artili
cial one. jokes William Little,
a physics professor here.
For the last live years Little
has been trying to build a
model ol the human brain. He
says he has made considerable
progress toyvard building an in
telligent being, even though
Ins mathematical model has so
tar simulated a network ol only
lour neurons on a computer.
This is a long way oil Irom the
billions <>i neurons in human
heads.
"The brain," said Little in a
recent interview, "does one
thing well and repeats it .ill the
time. Il you look at cortical col
umns (tlie lolds ol gray matter
in your head), they look the
same practically everywhere.
Little's model is built on this
apparent simplic ityon the local
level. So it appears that it is
only amatterot his ability to
build a more complex model
before he builds his immortal
thinking machine.
Little is applying methods
used in understanding com
plex physical systems such as
gases and superconductive
materials to the study ol
perhaps the most complex
physic al system the brain.
"In the past M) years physics
has made tremendous ad
vances through the develop
ment ol statistical mechanics in
the understanding ol strongly
interacting many-body sys
tems," he said. The theory of

superconduc tivity (where elec
trons interact at extremely low
temperatures), or the under
standing ol how gase>< con
dense are examples ot this.
Little says he realized that
the brain was |ust such a
many-hodv system with 10"
neurons interacting together,
and so is susceptible to the
same sort ol analysis.
Little's model has been es
sentially mathematu al, using a
function called an ' order
parameter," which in statistical
mechanics carries "the es
sen< c ot ,1 new phase ot a sys
tem."
"for example, a liquid has a
mathematical signature that
lets you know it is a liquid and
not a uas. It has a ditterent de-

Little's model is capable of making errors.
'In fact, that helps it. The errors give it access
to regions which, if it was deterministic, it
would never explore/ The ability to err, it
seems is beneficial.

gree of order Irom a gas. The
order parameter is a mathemat
ical tunc lion that describes the
transition irom one liquid to
the other.
"The thrust of modern
physics is that il you can recog
nize the order parameter, then
you have the essence ol the
state that you are trying to dis
cuss."

I ittle s model is an
isomorphism — an analogical
model.
"You can map one problem
into the other and make use of
the \ast amount that we know
about physical systems," said
I ittle.
I ittle s model simulates
many ot the actual (unctions of
the human brain and so may
provide answers to what are at
present open-ended questions
about the brain's operations.
Information is stored in the
brain in short- and long-term
memory, little theorizes that
short-term memory depends
on the neural firing in the vast
network that they comprise.
Long-term memory occurs at
the synapse, the place yvhere
neurons interact. Information

is stored here chemically.
The brain is a sophisticated
c omputer, but unlike a compu
ter 11 does not have a central
processing unit; inlormation is
processed throughout the sys
tem.
The way you remember
something is that what you
think or perceive acts as a cue.
New information stimulates a

memory in an analogous way
to the reference beam in a
hologram that allows us to see
an image rather than luzzy
lines on a strip ol tilm.
Many psychologists have
been skeptical about this idea,
mainly because where and
how the intormation is stored
remains unknown, little has
hypothesized the synapse to
be the location ol long-term
memory. "You would never
see it as having a holographic
property unless you use the
methods we use," he explains.
Unlike present computers,
Little's system does not require
much programming. It learns
by itselt, and little says he is
going to teach it like a child.
I ittle hopes to progress trom
a pattern recognition device to
a more or less immortal brain,
but that is lar oil in the tuture.
"People ask me, what
about emotion?' " said Little.
"That problem is handled
through a global change ot ac
tivity, an uncertainty in the
model which biases it toward a
certain action."
But will it leel pain? Is it
going to mimic our tiehavior,
say "ouch" and squirm; or will
it actually leel pain?
With tins question Little ad
mits he has some problems. "I
don't know how to ask that
question mathematically," he
laughs.
"There are so many connec
tions in a human brain, it learns
so many things that a single
stimulus doesn't give you a
simple response.'"
Little speculates that the
same is true lor pain. "A given
input is like the trunk ot a tree.
The information affects a vast
number ot branches; this is
why leelings like pain are so

difficult to express."
"When someone says that
theyarein pain, I think they are
simply saying that what we call
pain is the tree (in the analogy).
"Pain is the same sort ot
thing as when someone says, 'I
really enjoy that painting':
what does he mean by that? It is
all the things that the painting
means to you. It you try to nar
row it down by grabbing a
branch, that's not it. It is not a
leal either; it's the whole en
tity.
"In principle I know how my
network works; I can then
hope to localize whatever ac
tivity it is that describes a par
ticular teeling. I am not expect
ing a little man at the back ol
the head, but a specific phase
associated with the order
parameter."
So, will Little's model have a
lite ot its own ?
"Under certain conditions
you can have a (unction that
'bootstraps' itself." It is

through the order parameter
that Little hopes to see a
mathematical tunction "which
is associated with the beliel in
the sell."
But is it going to be con
scious?
"It will have the teeling ot
consciousness, and ii you
make it sutticiently complex
that would show up as a
mathematical tunction."
Being able to describe a cer
tain state ot Little's brain model
does not mean that it is pre
dictable, that in a sense it will
be capable ot tree choice.
"One ot the essential prop
erties ot our system is that it
takes noiseintoaccount. There
is a certain amount ot random
ability built into it. It can mod
ify itself.
People try to make comput
ers error-tree. Little's model
brain is perfectly capable ot
making errors; "in tact that

helps it. The errors give it ac
cess to regions which, it it was
deterministic, it would never
explore," said Little. The ability
to err, it seems, is beneficial.
little's artificial brain would
have quite an advantage over a
human brain. Since if will be
made out ot semiconductor
memory, it could absorb in
formation over long periods ot
time. It would be an immortal
being in the sense that it could
live tor thousands ol years.
"I don't known that is going
to give it any greater wisdom.
Certainly if could learn a lot
trom history," said Little,".. .
doesn't it sound like gre.|t
stutf?"
Ihere are some interesting
philosophical questions to be
answered, like whether it has
legal rights. Many people ask
Little whether his model will fry
to takeover the world. "I don't
see why it should want to," he
responded.


William Little
