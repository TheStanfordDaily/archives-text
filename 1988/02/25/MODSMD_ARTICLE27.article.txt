# Features
## Neural networks, the brainchild of the future? 
### Ingrid Wickelgren Science editor 
Leonardo da Vinci wanted to
fly. He looked at a bird and made
some wings. Three hundred years
later, humanity still couldn't fly.
Then humanity stopped trying
to emulate birds and learned the
principles of flying, propulsion
and lift, lifting the Wright broth
ers off the ground.
So much for biological analogs
is the moral of this story told by
Michael Genesereth, associate
professor of computer science at
Stanford. Genesereth disagrees
with an increasing number of sci
entists who think it is profitable
to build intelligence by modeling
another solution of evolution, the
human brain.

Intelligence, an emergent prop
erty of billions of neurons in the
human brain, will also emerge
from multiple interacting electri
cal units within a computer. Sci
entists ranging from cognitive
psychologists to electrical en
gineers have flocked toward a
study of computer neural net
works in hopes of both a greater
understanding of the brain and
more intelligent [and faster] com
puters.
Psychologists including Stan
ford Prof. David Rumelhart are
using neural networks to study
human cognitive processes. He
and other neural network re
searchers program computers
using algorithms or learning
rules, to solve problems. "Learn
ing" for a neural network means
altering the strengths of the con
nections between many small
neuron-like units.
"As people get closer to under
standing how single cells work,
there is a greater and greater need
to understand how aggregates (of
nerve cells) might work," Rumel
hart says. Studying computer
neural networks will be very valu
able to the neuroscientist, accord
ing to Rumelhart.

In a paper to appear in the Jour
nal of Memory and Language,
Stanford psychologists Mark
Gluck and Gordon Bower state,
"We believe the adaptive (neural)
network approach . . . has consid
erable potential for solving some
of the perennial problems of the
oretical psychology."
According to Gluck and Bower,
about 25 years ago "the theoret
ical view of memory was
revolutionized by ideas spun off
from the metaphors of informa
tion processing and the mind-as
computer."
Neural networks can learn new
information and often make in
ferences from that information.
Artificial intelligence (AI) pro
grams can combine discrete pieces
of knowledge in different ways,
allowing the production of new
knowledge.
With both methods, the "intel
ligent" computer can use infor
mation in different ways in dif
ferent situations, analogous to a
biological organism that can be
have differently in different envi
ronments.
But the analogy stops here in
AI.
Researchers in AI do not look
at the neuron. They do not look
at the brain. They do not even
think the human brain exhibits
the best possible intelligence.
Behind every working AI pro
gram lies transistors, but that
doesn't mean programs should be
designed by thinking about tran
sistors, according to Computer
Science Prof. Nils Nilsson.
"You don't design a bridge at
the level of nuts and bolts,"
Nilsson says."The argument is
not whether you can do it at that
level, but what's the best way for
an engineer to think about it."
Similiarly, to understand how
the mind works, people should not
look at individual neurons. "A
neuron has nothing to do with
the mind," Nilsson says.
Just as statistical mechanics, a
study of particles, won't explain
much about large bodies of air,
so studying individual neurons
won't help humanity understand
the macroscopic property of intel
ligence, Geneserthe says.
There is a science called ther
modynamics, says Genereseth,
that pays attention to macroscopic
properties. Thermodynamics is
analogous to the AI approach to
studying intelligence.
AI researchers study two ques
tions, according to Nilsson: What
information should the computer
be given and what language
should be used to convey that in

formation? AI researchers pro
gram discrete pieces of knowledge
into a computer, which they must
do in a special symbolic language
that the computer can under
stand.
Although in real life, intelli
gence and knowledge are repre
sented in the tens to hundreds of
billions of neurons and their con
nections in the brain, AI research
ers don't look at the biological
reality in such detail.
AI researchers think it is useful
to model the brain as if the facts
a person knows are actually there
— as if the mind stores beliefs
about the world, Genesereth says.
According to Genesereth,
neural net research will not tell
humanity anything about the
question it really wants to answer.
That question is not how can tiny
pieces be connected to produce
"intelligent" behavior nor even
how does the human brain
produce intelligence. The question
is: What is intelligence?
People don't agree. Various
people have defined intelligence
as the ability to perform difficult
tasks, learn from experience,
transfer knowledge from one sit
uation to another or use language
or cope with the general world,
according to Computer Scientist
Prof. Edward Feigenbaum.
Some philosophers, not com
puter scientists, believe that "ar
tificial intelligence" is an
oxymoron. They think intelli
gence, by definition, must be em
bodied in a living organism, ac
cording to Feigenbaum.
"Intelligence is not a substance
like energy or a fluid, but a prop
erty," says Nilsson. "It is an abil
ity to act appropriately in an en
vironment."
The environment depends on
the organism. A Paramecium, for
example, could be considered in
telligent if its behavior was well
suited to its situation. On the
other hand, it is not clear whether
humans are intelligent under this
definition. For instance, actively
developing the capacity to blow
each other up is "not very intel
ligent," according to Nilsson.
Intelligence, Genesereth says, is
"a property of a computational
system" of which humans are one
type, a type which does not exhibit
this property "all that well."
Humanity now has supersonic
airplanes.
"What we want is supersonic
intelligence," Genesereth says.
There are now mechanical
birds, but they came after supe
rior methods of flying. It may be
possible to produce artificial

humans, explains Genesereth, but
silicon men may come after the
production of machines that are
smarter than humans.
"Attempts to understand intel
ligence via neural networks are
like da Vinci strapping wings onto
the arms of men," Genesereth
says.
Nevertheless, in the last few
years, interest in neural networks
has surged, in large part because
of an advance made chiefly by
Rumelhart. The current brain
style computers are powerful only
because they contain multiple
layers of neuron-like units, an ad
vance over the first single layer
machines. Rumelhart figured out
how to make a multilayer network
learn.
Neural networks are very good
at solving problems involving
multiple constraints such as
image (or any kind of sensory)
processing. Pattern recognition,
for example, is easy for a neural
network because such networks
can process many things in par
allel, like the human brain.
Nilsson is not impressed.
Claiming that a neural network
can be wired up to solve con
straint satisfaction problems "is
not saying much more than that
you can wire up transistors to
solve certain adding problems,"
Nilsson says.
"Rumelhart and people like him
are going to make a contribution,
but at a low level of detail .. .
They won't explain much about
intelligence," according to
Nilsson.
One of the more interesting

functions a neural network can
perform is to generalize, so that,
after learning specific informa
tion, it can act appropriately when
given related information. This is
Gke a human who learns the word
"cat" and the letter "h" and so
can read the word "hat" upon
seeing it for the first time.
Using a neural network ap
proach, a computer has been
taught to generalize about the
pronunciation of English words.
Terrence Sejnowski, professor of
biophysics at John Hopkins Uni
veristy and Charles Rosenberg,
professor of psychology at Prince
ton University, have programmed
a computer to pronounce novel
words after they trained it on
strings of continuous speech.
For every successful application
of a neural network there are
probably hundreds of successful
A 1 programs. However, this is
only because efficient computer
neural networks are too new to
support a large number of
developments.
Artificial neural networks were
first popular in the early 19605.
At about this time, the first neural
computer, called a "perceptron"
was developed by Frank
Rosenblatt. This neural comput
er, with only a single layer of
neural elements, was unable to
solve some very simple problems,
causing many scientists to lose
interest in the approach.
Nilsson, who wrote a book
about neural networks in 1965,
was one of the sceintists who lost
interest.
Neural networks attract scien

tists not only because the ap
proach shows promise, but also
because the current rate of prog
ress in AI has been frustratingly
slow for some.
AI boasts three mcyor type of
achievements, according to
Nilsson. First is the development
of expert systems that can do
everything from diagnosing infec
tious diseases to trouble-shooting
the molding of plastic parts.
Second is progress in robotics,
specifically in machine vision. Fi
nally, AI has advance natural lan
guage processing, research geared
toward helping a computer un
derstand the language people
speak and type.
However, AI has a lot farther
to go, admits Nilsson. Expert sys
tems are very inflexible. They "fall
apart drastically" when con
fronted with an unfamiliar situ
ation. For example, they cannot
use a familiar word in an un
familiar context.
AI has a long way to go in ma
chine vision as well. AI programs
that recognize parts of a scene
work as long as the parts are
simple and the background is
simple.
"We're marching up the evolu
tionary scale of intelligence, but
it's a long scale," Nilsson says.
"What we realize in AI is just
how big that scale is — and how
hard it is to build programs that
go up just one more notch."

Of Matter and Time researches
Stanford science and appears
every Thursday.


