# Physics model helps prof. explain learning
## Spinning up or down to remember? 
### Jock Friedly Staff writer 
A glass of red wine may bring back fond
memories of a beautiful October night in
Paris. A favorite baseball cap may recall the
first home run in an old-timer's career.
This kind of "associative" thinking led Stan
ford Physics Prof. William Little to relate a
purely mechanical phenomenon with the func
tions of human memory.
The theories of Little have led to his being
described as a "futurist." And Little's model
of the brain is one example that fits this
description.
Instead of studying the biology of the brain,
Little has been studying the statistical me
chanics of a network of electrons, or a "spin
system" for nearly 15 years. His research on
electron systems as applied to neural networks
has led to an explanation of how learning
could work, and he has determined a possible
location for where memory resides in the
brain.
The study of neural networks has blossomed
into a hot area of research within the last

few years, drawing researchers from such di
verse fields as psychology and biology to
physics and electrical engineering.
"What I was trying to do was to see if I
could understand the way the brain might
work by analogy with another system," Little
said.
Little "mapped" a neural network model
onto a spin system and by analogy, he was
able to show how learning and recall could
take place.
Little showed that a pattern sent through
the spin system could later be "recalled" by
a recall cue. If the same pattern was sent
through again, that pattern would come back
out again. Recall can be thought of as a
recognition ability in the same way that after
a face is seen it can be recognized when seen
again.
"Associated recall" is another property that
Little is able to explain through his model.
If a pair of objects is memorized, then given
one of those objects as a cue, both of these
objects will be recalled-a very important aspect
of basic learning.
Perhaps most importantly, Little has even

determined where memory might be stored
in the brain. He found that it had to be
located in the synaptic junctions, the connect
ing regions between the cells of the nervous
system.
Little founded the network model of the
brain on a phenomenon known in physics as
the Ising spin. The Ising spin model describes
the interaction of electrons, negatively charged
atomic particles, based on their "spin." Spin
is a characteristic of subatomic particles that
is related to its magnetic interaction with
other particles.
Physicists have labeled two types of char
acteristic electron behavior as "spin up" and
"spin down."
Little bridged the gap between physics and
biology when he recognized a possible corre
spondence between these subatomic qualities
and the nervous system. He saw that spin
could apply to neurons, which are complex
cells of our nervous system that send and
receive sensory information."Spin up" could
represent a neuron just fired to relay a mes-

sage, and "spin down" could rep
resent a neuron at rest.
A linear spin system like the
Ising model describes how the
spin of a given electron can influ
ence the spin of its closest neigh
bors. In the same way, a neuron
firing could cause a neighbor
neuron to fire, thus passing on a
message through the neural net
work.
Little first realized the connec
tion about 15 years ago when he
was asked to attend a NASA con
ference for "futurists," distin
guished thinkers studying future
trends. Such well-known futurists
as Arthur Clarke, author of
"2001: A Space Odyssey," and
rocket scientist Werner von Braun
attended the same gathering.

Little was chosen as a futurist
because of his bold theory pub
lished in the mid-1960s about su
perconductors, materials with no
electrical resistance. Little pre
dicted that superconductors
would be created at room
temperature, an almost unheard
of prospect until a couple of years
ago when great advances were
made to produce superconductors
well above absolute zero.
A lecture on the newly
emerging field of neurobiology
given at the conference sparked
Little's interest. Coming from a
background in physics, Little
quickly approached the issues
raised in the speech from a com
pletely different angle. He related
it to the Ising spin system which
he had encountered in studying
statistical mechanics.
As with his early superconduc
tor theory, Little's enthusiasm for

his neural network research was
not shared by other physicists.
They said his linear model would
not work because the brain was
inherently non-linear since infor
mation coming in to the system
would have to be able to change
information already in the net
work. Otherwise, the memory
could never change and learning
would not occur.
Little did not want to com
pletely abandon his linear model,
but faced with non-linearity,
Little had to back down.
To a scientist, non-linearity is
a curse. Even very common non
linear systems in nature are not
well-understood in general, and
non-linearity leads to unpredicta
ble chaos.
Little's ability to explain the
brain using the spin model anal
ogy would have been doomed if
he had been forced to employ a

non-linear model. Even with the
most powerul supercomputers,
Little would have been unable to
calculate the behavior of non
linear systems.
Little, an undaunted futurist,
struggled with the problem of
non-linearity until he read about
a common medical phenomena.
After a heavy blow to the head,
humans will often lose the
memory of what took place a few
seconds before the collision.
Little interpreted this as proof
that a linear model could be used.
The information just taken in,
stored in short-term memory, did
not reach long-term memory for
a couple of seconds. The initial
input to the neural system, oc
curring on the scale of micro
seconds, does not therefore inter
fere with what is already stored
in the memory until a few seconds
elapse.

Instead of being forced into a
non-linear model, Little produced
his linear model using perturba
tion calculations, small changes
that would only affect the system
after a long time. This new ap
proach explained how the memory
was not deformed by information
coming in, but also how it could
affect it over a long period of time.
One of the earliest concerns for
Little was to understand how the
brain, with all of its activity, could
actually keep order among a back
ground of "noise".
"How could you have, in such
a noisy environment, something
that .. . you can think about and
keep thinking about over an ex
tended period of time," Little said.
Comparing this to the spin sys
tem, the noise in the brain cor
related with the perturbation of
the electrons caused by their tem
perature.

Despite Little's successes with
the model, he still has not found
a way for the brain to generalize.
Generalization is absolutely essen
tial to recognize something in a
setting that has not been seen
before.
The failure to generalize is one
of the major difficulties in the
field of artificial intelligence.
Generalization is the primary fea
ture of learning that needs to be
understood in order to make
"smart" computer programs. Ef
fective learning is not possible
without generalization, and a pri
mary goal in the study of artificial
intelligence is to find methods to
generalize learning.
Although he has not yet
succeeded, Little said he hopes to
explain the capacity to generalize
using the same neural network
model that so far accurately
describes association.
