# Science
## AI is not simply sci-fi Scientists making strides in artificial intelligence 
### Jim Morris Staff writer 
Unlike most of Silicon Valley's
towering, tinted-glass computer
research structures, Stanford's
Center for the Study of Language
and Information resides in a
charming two-story cottage
turned-office building. But there's
more than just an architectural
difference between CSLI and
other local research facilities —
Stanford's center takes a totally
different approach to cutting-edge
artificial intelligence (AI)
research.
AI is the process of giving a
computer reasoning and learning
abilities. There are two types of
AI: "strong" AI and "weak" AI,
according to Raymond Perrault, a
member of the CSLI faculty and
the director of the AI center at
SRI International.
The difference between the
CSLI and other Silicon Valley
facilities lies in the type of AI
research being done and the way
that research is approached.
CSLI, on the forefront of AI
research, is currently working on
hybrid-systems that combine
weak and strong AI. According to
scientists, these systems are the
wave of the future and may lead
to the ability for computers to
learn from mistakes.
Founded in the '70s and early
'80s, when computer scientists
realized that bridging the gap
between human intelligence and
computer "intelligence" was a
problem that could not easily be
solved, CSLI approaches AI
research by trying to learn the
basics of AI before diving into
complex systems.
"Computer scientists found
out when they tried to model the
behavior of the human mind and
how it communicates, the basic
research on these subjects was
incomplete," said Linguistics and

Philosophy Prof. Tom Wasow.
According to John Etche
mendy, CSLI's director and pro
fessor of philosophy, the problem
is similar to the advent of engi
neering. Basic research in physics
led to the applications of engi
neering. Thus, basic research in
natural language of humans must
be completed before computations
simulating human behavior can
be programmed.
As a result, CSLI has brought
together the expertise of Stan
ford's philosophers, linguists, logi
cians and psychologists to work on
artificial intelligence problems.
In the human mind
At CSLI, strong AI research
takes computer reasoning to a
higher level by trying to simulate
the physical human brain as well
as its behavior.
Strong AI performs intelligent
tasks in a way that directly mim
ics the way humans do the task,
Perrault said.
Research in strong AI, perhaps
the closest step to a truly human
like computer, is sometimes
referred to as connectionism.
A typical computer uses one
fast processor to accomplish its
tasks whereas the brain employs
the idea of connectionism — a
combination of several slower pro
cessors (neurons) that collectively
are faster than a single processor.
"In the human mind resides the
capacity for language, thinking
and reasoning. In the human brain
resides the squishy stuff, the tis
sue, the neurons and the chemi
cals," said Psychology Prof. David
Rumelhart, a member of the CSLI
faculty. "My software program, by
emulating the brain's neurons,
neuron-like interactions and com
putations, simulates the mind-like
behavior of intelligence."
Rumelhart said the general
purpose of his research is to
understand how everyday people

operate, in terms of biology, and
to find out how the human mind
emerges from the human brain.
'Expert systems'
Although strong AI resembles
the human brain, most AI
research falls into the category of
weak AI — programs that exhibit
intelligent behavior without mim
icking human processes.
"The best chess-playing pro
grams today are examples of weak
AI," Perrault said.
"Expert systems," an example
of weak AI, are a main focus at
Stanford's Knowledge Systems
Laboratory. "These systems are a
set of rules for accomplishing cer
tain tasks. They are a store of
knowledge intended to produce
quick, consistent, expert advice,"
Perrault said.
An example of an expert sys
tem would be a program that
monitors the life signs of an
intensive care unit patient and
reacts accordingly to changes in
the state of the patient. The com
puter's reactions would be pat
terned after the expertise of doc
tors who have experience in inten
sive-care wards.
Wasow described a machine
translator that is another exam
ple of a weak AI system. The
machine translates words from
English to French.
It used the Canadian Parlia
ment transcripts, written side by
side in French and English, as a
model to statistically derive the
probability that certain words will
occur in conjunction with each
other.
However, the program does not
"understand" the language and
this leads to a lack of versatility.
Strong - weak AI
Wasow, a linguistic expert by
training, envisions the future of
AI research to be a combination of
the weak and strong types of AI.

"The statistical method of
approaching AI will not be the
final answer, but it will augment
the current theoretical ideas of
AI," he said.
Work towards a universal
translator like those seen in "Star
Trek" or "Star Wars" - that
translate one language into
another instantaneously — is an
example of a strong-weak hybrid
AI project that is happening at
CSLI.
However, researchers shy
away from predicting the suc
cess of this work because there
is still a lot to learn about
human conversation, the struc
ture of our language and simi
larities between unrelated lan
guages like Japanese and
English.
Incremental developments
like finding similarities in

entirely different languages are
steps that are progressively
moving AI towards the goal of
giving computers the tools to
decipher and translate two
entirely different languages
instantaneously.
Another weak-strong AI
hybrid project at CSLI is a com
puter program called Hyperproof,
developed by Etchemendy and his
colleague Jon Barwise, a profes
sor of philosophy, formerly at
Stanford, but now at Indiana Uni
versity.
This software, about half the
size of the Microsoft Word pro
gram, turns the computer into a
reasoning tool. This reasoning
takes the shape of proofs that
compare written language with
graphical evidence; a process
roughly similar to creating
proofs in a high school geometry

class.
The computer presents the
user with graphical evidence and
the user then writes a proof to
support the given hypothesis.
With the Hyperproof program,
proofs can be accomplished with
greater efficiency than human
calculations.
The "intelligence" of the pro
gram comes into play when the
computer checks the correctness
of the logic. Etchemendy uses
Hyperproof in his undergraduate
course on the language of logic
and is currently developing a sec
ond version that will assist the
user in the actual formation of a
logical proof.
The program is an example of
how the center, by means of AI, is
working to bring a computer's
reasoning closer to intuitive
human reasoning.


Jeff Sorrentino — Daily
