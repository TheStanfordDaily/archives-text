# Science
## Neurons: they make your brain tick 
### ERIC KEISMAN 
Editor's note: This article is the first in
a series of four articles smveying press
ing questions at the frontiers of modern
neuroscience.

1 ickingaway inside ol us, every
moment that we are awake, and
many moments that we are not, is
this elaborate thinking machine
known as the mind. Philosophers
across the ages have pondered
what the essence of the mind is,
quarreled about its inner work
ings and basically scratched their
collective heads about it.
Scratching their heads was,
more 01 less, all that they could do.
But that has begun to change.
How does the mind work? The
20th century has seen this ques
tion explode from the realm of
philosophical introspection onto
the playing field of scientific in
quiry.
Neuroscience, as this loose con
glomerate of disciplines is known,
is practically bursting at the seems.
The 29th annual Society lor Neu
roscience meeting, held this past
October in Miami Beach, boasted
more than 24,000 attendees.
If the workings of the mind
were a giant jigsaw puzzle, then
ten- the last few decades, neiuosci
entists have been busily spilling of
all of the pieces out onto the table.
Now, they are picking those pieces
up one by one, examining then
shapes and beginning to put them
together.
This series of articles will at
tempt to provide a snapshot of the
state of the art in this endeavor.
Starting with the neuron, the basic
functional unit of the brain, we
will work our way up through sim
ple neural circuits, like reflexes, to
more complex circuitry that might
actually store 'information' as we
know it. Then we will make a giant
leap to the familiar, day-to-day
fluxions of the brain, such as
ftlniory.
* each stop along the way, we
will pause to outline some princi
ples of neural organization and
hopefully come away with a feel
for the kinds of questions that re
searchers are asking neuro
science.
At last count, the human brain
contained around 100 billion neu
rons, and no one debates that
these cells, with their pec uliar con
figurations and connections, are
what endow the brain with its re
markable properties. What, exact
ly, is it that neurons do that enable
them to be part of this thinking
machine?
We asked Prof, of Molecular
and Cellular I'hysiolog) Dan
Madison, a neui obiologist at the
Medical School, to help us answer
this question.
In the simplest sense, neurons
are the components of the brain,
in much the same way that transis
tors are the basic functional unit

underlying modern electronics.
1 lowever, a transistor has just two
inputs and one output, while a
neuron c an have many thousands
of inputs and outputs.
I he transistor analogy "doesn't
really come close to describing the
full properties and abilities of a
neuron," said Madison. "Name
the electronic component you
like, and a neuron likely does it."
How?
Neurons are highly specialized
cells whose cell membranes have
been elaborated into structures
that are designed to receive and
transmit information. The inputs
to a neuron are called dendrites,
branches in a tree-like structure
which connects to the cell body.
I he outputs of a neuron are called
axons, which are long, thin ten
drils that can travel for some dis
tance away from the neuron.
When a neuron 'fires,' the axon
c arries this signal to the target cell,
which in the brain is usually an
other neuron. 1 he* connections
between neurons are called
synapses, which are places where
the two c ells come extraordinarily
close together.
I he signal jumps across the
synapse in the form of a neuro
transmitter that is literally 'squirt
ed' out the end of the axon and is
detected by the receiving cell.
Neurons can compute because
their unique design enables them
to weigh multiple inputs. As elec
trically ac tive cells, neurons have
an electric charge across their cell
membrane called a membrane po
tential. When they receive an
input at their dendrites, this caus
es a change in the membrane po
tential.
If this change hits a certain
threshold, the neuron fires. In
puts can be both excitatory, which
prompt a neuron to fire, or in
hibitory, which tell the neuron not
to fire. Usually, a single neuron is
receiving more than one input.
"Generally, in the central ner
vous system," said Madison, "one
neuron's input is not strong
enough to get a downstream neu
ron over threshold, so that's why
you have integration."
A neuron computes, even
'thinks,' in the simplest sense of
the word, when it integrates the
varied inputs it is receiving and
decides whether or not to fire.
If neural circuits were fixed,
then they would be very uninter
esting indeed, much like the dedi
cated circuits in a simple appli
ance. Ihe real flexibility in the
nervous system derives from an
other important property that
neurons have: They can change
their connections.
This versatility underlies both
the shifting mental states that are
our moods and thoughts and the
long term changes that make up
our memories. There are two
ways that neurons can change
how tliev are wired up to other

neurons. One way is known as
modulation, which is used to make
rapid, short-term changes.
A special class of neurons iu the
brain, known as modulatory neu
rons, do not actually carry specific
information. Instead, they regu
late the flow of information be
tween other neurons, like neural
traffic signals.
When a modulatory neuron
that neuron ff fistens'
to the signals from other neurons.
Madison likens this effect to the
controls 011 a radio. Some modula
tory neurons just turn up the vol
ume on the radio, that is, they de
termine how loudly a neuron
hears its inputs. This has the net
effect of making that neuron more
active.
Other modulatory neurons ac
tually 'change the station;' they se
lectively tune out some of a neu
ron's inputs in favor of others. Ef
fectively, this changes the connec
tions between neurons.
The effect is a transient one,
though. Modulatory neurons do
not actually alter the structural
connections between neurons;
that would be too drastic lor short
term processes.
"The body in general, and the
nervous system in particular,
doesn't spend energy 011 some
thing that it doesn't need too,"
said Madison. "On a moment to

moment basis, you probably don't
want to have a structural c hange.
Structural changes are expen
sive."
He adds that "we know the
properties are there to radically
c hange the function of a neuron
or .1 circuit" using modulation,
which makes it idealh suited to
subserve the short term changes
in our brain, like thoughts that
change from one moment to the
next.
What about long term changes,
like memory? Here, the efficiency
argument cuts the other way.
Modulation requires the constant
activity of the modulatory neuron.
1 his is fine fora few minutes, but
over clays and weeks, it c an get ex
pensive.
"In that case, it's cheaper to
build something" Madison said.
"[This] may involve things like ac
tually making physical c hanges in
the c ircuit, growing a new connec -
tion or building a stronger con
nection where you have one al
ready."
These various long term struc
tural changes are known as neural
plasticity. One kind of neural
plasticity, known as I.IT, or "long
term potentiation," is thought to
be particularly important in the
formation of long term memories
and associations.
L LP has the remarkable prop
erty that it allows the neuron to

strengthen a synaptic input when
that input that becomes highly ac
tive. I his seems to be based in the
logic that if an input is being used
frequently, it must be important.
So the neuron turns up the vol
ume. More remarkable still is that
this volume control displays
'specific ity:' It only effects that one
synapse.
Thus, a neuron can make selec
tive, long term adjustments 10 how
carefully it listens to each individ
ual input. Many researchers be
lieve that memories and other
neural habits are actually encoded
in these s\ naptic strength settings.
Much of Madison's own re
search has focused 011 elucidating
the mechanism behind LIP,
which is one of the more challeng
ing and contentious problems in
neurobiology. Ihe controversy
has centered around just what ex
act.lv changes at the svnapse to
strengthen the neural connection.
I lie strength of a synapse de
pends 011 how loudlv the transmit
ting, or pre-synaptic, neuron
'speaks' and how hard the receiv
ing, or post-svnaptic, neuron is
listening.'
Literally, this corresponds to
the amount <>l neurotransmitter
released In the pre-synaptic neu
ron and the number of neuro
transmitter receptors deployed at
the svnapse In the post-synaptic
neuron.

Researchers want to know
whether the strength of the
synapse increases because the
post-synaptic neuron listens more
intently or because the presynap
tic neuron speaks more loudly.
Though the controversy is by
no means resolved, Madison be
lieves present evidence favors the
former. One ingenious experi
ment centers around a special
kind of cell that cleans up the neu
rotransmitter after a synapse has
fired. Scientists reasoned that if
L I 1' was due to increased neuro
transmitter release, these cells
would be busier after a synapse
was strengthened.
They were not, which strongly
suggests that the bulk of the
change is in the receiving cell.
Knowing the properties of in
dividual neurons offers important
dues as to how they function in the
brain as a whole. For instance, the
ability of L I P to alter individual
neural connections gives us an
idea of how flexible a single neu
ron can be and how much infor
mation it can store.
" The more we know about neu
rons," Madison said, "the more
complicated tliev become and the
more they seem to be able to do,
the more possibility you can see
for them being able to store
a lot of information.
"Neurons," he added, "proba
bly do more than we imagine."


Anatomy of a neuron
The dendrites receive information from other neurons. The
neuron then decides whether to fire an action potential down
its axon. The action potential is transmitted to the next neuron
across a synapse [inset]. At the synapse, neurotransmitter is
released from packets called 'vesicles' and is detected by
neurotransmitter receptors on the 'post-synaptic' cell.
