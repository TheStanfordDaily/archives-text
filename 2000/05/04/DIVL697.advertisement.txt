# Adv. 11 Page 8
## 
### 
V s ■ \PPI < ' ' s
ACM Allen Newell Award Lecture
COMPUTERS
AND TRUST
■v ' . v-■
Professor Nancy Leveson
Massachusetts Institute ol Technology
1999 ACM Newell Award Recipient
Thursday
May 4, 2000
4:30p0i
Terman Auditorium
COMPUTERS AND TRUST
"We seem not to trust one another as much as would be desirable.
In lieu of trusting each other, are we putting too much trust in our
technology?" IS. Sheridan.
Computers are being introduced into the control of virtually every
dangerous system, including nuclear weapons, transportation
systems (aircraft, automobiles, trains), medical devices, and
chemical and nuclear power plants.
Few engineering techniques exist to provide assurance that safety
is not being degraded by the substitution of digital systems for the
electromechanical designs that have been perfected through
decades and sometimes centuries of experience. At the same
time, nothing is absolutely safe, and computers provide important
advantages over the human operators; social systems, and
engineered devices they are replacing.
This folk will attempt to examine whether concern is
justified.
Are we putting too much trust in computers?
Will introducing computers to assist or replace human
operators eliminate or reduce the problem of human error?
Are there limits to the reasonable uses of computer
technology?
If so, what do we need to do to stretch those limits?
V s ■ \PPI < ' ' s
ACM Allen Newell Award Lecture
COMPUTERS
AND TRUST
■v ' . v-■
Professor Nancy Leveson
Massachusetts Institute ol Technology
1999 ACM Newell Award Recipient
Thursday
May 4, 2000
4:30p0i
Terman Auditorium
COMPUTERS AND TRUST
"We seem not to trust one another as much as would be desirable.
In lieu of trusting each other, are we putting too much trust in our
technology?" IS. Sheridan.
Computers are being introduced into the control of virtually every
dangerous system, including nuclear weapons, transportation
systems (aircraft, automobiles, trains), medical devices, and
chemical and nuclear power plants.
Few engineering techniques exist to provide assurance that safety
is not being degraded by the substitution of digital systems for the
electromechanical designs that have been perfected through
decades and sometimes centuries of experience. At the same
time, nothing is absolutely safe, and computers provide important
advantages over the human operators; social systems, and
engineered devices they are replacing.
This folk will attempt to examine whether concern is
justified.
Are we putting too much trust in computers?
Will introducing computers to assist or replace human
operators eliminate or reduce the problem of human error?
Are there limits to the reasonable uses of computer
technology?
If so, what do we need to do to stretch those limits?
V s ■ \PPI < ' ' s
ACM Allen Newell Award Lecture
COMPUTERS
AND TRUST
■v ' . v-■
Professor Nancy Leveson
Massachusetts Institute ol Technology
1999 ACM Newell Award Recipient
Thursday
May 4, 2000
4:30p0i
Terman Auditorium
COMPUTERS AND TRUST
"We seem not to trust one another as much as would be desirable.
In lieu of trusting each other, are we putting too much trust in our
technology?" IS. Sheridan.
Computers are being introduced into the control of virtually every
dangerous system, including nuclear weapons, transportation
systems (aircraft, automobiles, trains), medical devices, and
chemical and nuclear power plants.
Few engineering techniques exist to provide assurance that safety
is not being degraded by the substitution of digital systems for the
electromechanical designs that have been perfected through
decades and sometimes centuries of experience. At the same
time, nothing is absolutely safe, and computers provide important
advantages over the human operators; social systems, and
engineered devices they are replacing.
This folk will attempt to examine whether concern is
justified.
Are we putting too much trust in computers?
Will introducing computers to assist or replace human
operators eliminate or reduce the problem of human error?
Are there limits to the reasonable uses of computer
technology?
If so, what do we need to do to stretch those limits?
V s ■ \PPI < ' ' s
ACM Allen Newell Award Lecture
COMPUTERS
AND TRUST
■v ' . v-■
Professor Nancy Leveson
Massachusetts Institute ol Technology
1999 ACM Newell Award Recipient
Thursday
May 4, 2000
4:30p0i
Terman Auditorium
COMPUTERS AND TRUST
"We seem not to trust one another as much as would be desirable.
In lieu of trusting each other, are we putting too much trust in our
technology?" IS. Sheridan.
Computers are being introduced into the control of virtually every
dangerous system, including nuclear weapons, transportation
systems (aircraft, automobiles, trains), medical devices, and
chemical and nuclear power plants.
Few engineering techniques exist to provide assurance that safety
is not being degraded by the substitution of digital systems for the
electromechanical designs that have been perfected through
decades and sometimes centuries of experience. At the same
time, nothing is absolutely safe, and computers provide important
advantages over the human operators; social systems, and
engineered devices they are replacing.
This folk will attempt to examine whether concern is
justified.
Are we putting too much trust in computers?
Will introducing computers to assist or replace human
operators eliminate or reduce the problem of human error?
Are there limits to the reasonable uses of computer
technology?
If so, what do we need to do to stretch those limits?
V s ■ \PPI < ' ' s
ACM Allen Newell Award Lecture
COMPUTERS
AND TRUST
■v ' . v-■
Professor Nancy Leveson
Massachusetts Institute ol Technology
1999 ACM Newell Award Recipient
Thursday
May 4, 2000
4:30p0i
Terman Auditorium
COMPUTERS AND TRUST
"We seem not to trust one another as much as would be desirable.
In lieu of trusting each other, are we putting too much trust in our
technology?" IS. Sheridan.
Computers are being introduced into the control of virtually every
dangerous system, including nuclear weapons, transportation
systems (aircraft, automobiles, trains), medical devices, and
chemical and nuclear power plants.
Few engineering techniques exist to provide assurance that safety
is not being degraded by the substitution of digital systems for the
electromechanical designs that have been perfected through
decades and sometimes centuries of experience. At the same
time, nothing is absolutely safe, and computers provide important
advantages over the human operators; social systems, and
engineered devices they are replacing.
This folk will attempt to examine whether concern is
justified.
Are we putting too much trust in computers?
Will introducing computers to assist or replace human
operators eliminate or reduce the problem of human error?
Are there limits to the reasonable uses of computer
technology?
If so, what do we need to do to stretch those limits?
V s ■ \PPI < ' ' s
ACM Allen Newell Award Lecture
COMPUTERS
AND TRUST
■v ' . v-■
Professor Nancy Leveson
Massachusetts Institute ol Technology
1999 ACM Newell Award Recipient
Thursday
May 4, 2000
4:30p0i
Terman Auditorium
COMPUTERS AND TRUST
"We seem not to trust one another as much as would be desirable.
In lieu of trusting each other, are we putting too much trust in our
technology?" IS. Sheridan.
Computers are being introduced into the control of virtually every
dangerous system, including nuclear weapons, transportation
systems (aircraft, automobiles, trains), medical devices, and
chemical and nuclear power plants.
Few engineering techniques exist to provide assurance that safety
is not being degraded by the substitution of digital systems for the
electromechanical designs that have been perfected through
decades and sometimes centuries of experience. At the same
time, nothing is absolutely safe, and computers provide important
advantages over the human operators; social systems, and
engineered devices they are replacing.
This folk will attempt to examine whether concern is
justified.
Are we putting too much trust in computers?
Will introducing computers to assist or replace human
operators eliminate or reduce the problem of human error?
Are there limits to the reasonable uses of computer
technology?
If so, what do we need to do to stretch those limits?
