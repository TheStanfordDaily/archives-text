# Opinions
## Editorial Course evaluations should be online 
### 
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
We are now midway through fall
quarter, and, instead of reading this,
you should probably be studying
for your midterm in three hours. But. al
though it seems far away, studying for final
exams and then picking and registering for
winter classes will soon be upon us. And with
that, we would like to take the opportunity to
ask the University to make serious reforms
to the course evaluation process.
As it currently stands, course evaluations
are handed out during the last class session,
usually at the end of class. Professors can only
hand them out to students who are there, and
usually only a few students are willing to stay
late to finish a thorough evaluation. Thus,
evaluations have a strong selection bias to
wards the opinions of those who attended
class regularly and felt engaged. We'd expect
the results of these evaluations to be skewed
towards the ends (positive and negative), and
probably to be too positive overall. Given
this bias,our biggest concern with the current
evaluation process is its lack of usefulness to
professors, teaching assistants and students.
What can professors and TAs glean from
evaluations that might be so slanted, and
how, realistically, can they even tell? If the
University is sincerely interested in using
evaluations (and thus undergraduate teach
ing) in the tenure process, what can they take
from the results? What can students use from
the comments and aggregate measures post
ed on the Courseguide if they are not repre
sentative of the class?
Distributing evaluations on paper is inef
ficient. Evaluations are all eventually en
tered into computers to aggregate data, to
make it anonymous and to provide informa
tion to professors,TAs and students. Printing
evaluations is both unnecessarily costly and
environmentally-unfriendly.
Thus, the University should move course
evaluations to an online system in order to
reduce waste and cost. It should consider
making evaluations mandatory before re
leasing grades, as Harvard does, and tying a
thorough evaluation to a small portion of the
grade, as some engineering classes already
do.
Just asking students to complete online
evaluations at some point toward the end of
the course is unlikely to be successful in im
proving or maintaining the current response
rate. So a small bonus for students to com
plete a thorough evaluation — a 15 minute
endeavor at most — would be a great incen

tive. Alternatively, the University could con
sider requiring that students complete evalu
ations in order to access their grades on
Axess. Such a process would allow students
to give candid opinions about the class while
blind to their grades. The requirement would
raise response rates to near-100 percent lev
els, could be done online and could tie stu
dents' actual grade (not their expected
grade) to their evaluation.
Another advantage to online evaluations
is a near immediate update of next quarter's
Courseguide. New sequences and professors
could be evaluated immediately, and all com
ments, not just a selection, could be available
to students who wanted a thorough review of
a professor. This would require even tighter
integration between the Courseguide and
Axess, but this service should be University
funded anyway (not by the inefficient ASSU
as it currently is), since satisfied students are
the University's best customers.
Online course evaluations have been
tried mid-quarter in some departments. At
that point, students feel like their opinion can
change their experience in a class, so they are
likely to contribute. At the end of the quarter
students have to be less selfish, but if they
were assured, say, by immediately seeing the
results of their comments on Courseguide,
evaluations would quickly become more
thorough and more useful to everyone in
volved.
Speeding up the evaluation policy would
also pave the way for one other reform that
the Editorial Board has advocated. If stu
dents thought they could understand courses
through online syllabi, reading lists and a
thorough Courseguide, the shopping period
could be trimmed and students could be en
couraged to shop classes before the quarter
starts.
All things being equal, the Editorial
Board would prefer that the University insti
tute as few mandatory requirements as possi
ble to increase response rates and reduce se
lection bias. But, at the same time, we remain
concerned about the way evaluations are
used and their overall usefulness. Moving to
an online course evaluation system and insti
tuting reforms to increase response rates
would be less expensive, friendlier to the en
vironment and more useful to administrators
and students. We encourage the University to
reflect upon the evaluation process now in
order to improve the system during this aca
demic year.

Unsigned editorials in the space above represent the views of the members of The Daily's editorial board. The
board consists of two Daily editorial staffers and six community members at-large. Any signed columns and
contributions are the views of their respective writers and do not necessarily
represent the views of the editorial board.
