# Down with testing!
## 
### 
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
Pcr*pi'ca*cious( adj.) — of acute mental iits
cemment (Webster's Dictionary)
As I sat mulling over the meaning of
the word "perspicacious" in my
ORE preparation book, I realized it
had a much greater significance. GRE
stands for Graduate Record Examination
— for most applicants to graduate school,
this is their version of the SAT. Apparently,
familiarity with the definition of "perspica
cious" is a measure of how well you might
do in graduate school. You can imagine my
surprise when two of my professors, who
had both attended prestigious graduate
programs and were now well-respected
scholars.could not define the word. I low did
they get into graduate school?
Both the SATs and the GREs, as well as
other standardized tests, are administered
by the non-profit Education Testing Ser
vices (ETS). According to their Web sites,
the SAT is apparently "a measure of the
critical thinking skills you'll need for aca
demic success in college," while the GRE
"providefs] common measures for compar
ing the qualifications of applicants and aid
in evaluating grades and recommenda
tions." And how does the word "perspica
cious" fit into all of this?

These tests contain writing, verbal and
math questions. But if you want to be an
English major in college, who cares if you
can find standard deviations? Four years
later, that same English major, who then de
cides she wants to go to graduate school, has
to take yet another test that measures her
ability to solve for x and find interest rates.
What does any of this have to do with a
Ph.D. in English?
Our English major will then be asked to
write two essays in a little over an hour in
order to test her critical thinking and writing
skills. Funny enough, she has already sub
mitted a 35-page writing sample about
Shakespeare with her application. What
does a quickly-written essay for or against
the almost absurdly philosophical and dra
matic statement,"The past is no predictor of


Vesikol &
Vinni Intersimone
At the Margins
the future," add to her application?
Ihis is a question for a historian,and
one that requires research. I see no
reason why an applicant to a chem
istry program should have to argue
about this statement for 30 minutes
in order to prove her worth.
And what about the verbal sec
tions of these tests? As most test
preparation books will tell you,
the test makers are not testing
your knowledge or your thinking
abilities, but rather your capacity
to guess what they're thinking.
( That's right, they want to know
how man\ applicants are psychic!)
So when \<ui get a question that
asks you for the opposite of a
word, the) want their opposite.
When the\ ask you to interpret a
paragraph, they want their inter
pretation When they want you to
correct the grammar of a sen
tence, the> want their grammar.
And when they ask you to write an
essav. they want their writing style.
As main I nglish professors, pro
fessional writers, linguists and an
thropologists will tell you. language
is used very differently by different
people Interpretations vary even
among professionals. Writing styles
are drastically different among writ
ers. And yet, the ETS feels that they
have the right to tell you how to
think, how to write, how to interpret
and how to use language. Language
changes over time and language
varies between locations. Ask a
British person, an American and an
Indian to define a word, and they
might give you three distinct defini
tions. These definitions are all cor
rect. because meaning is historically
and geographically specific. "Cor
rect" language is only "correct" be
cause the people with power say so

— hut there's nothing "correct"
about it. The only thing these tests
might measure is how well you can
fake ETS language.
If you are a white, middle- or
upper-class male whose first lan
guage is English, your chances of
faking ETS language are much bet
ter — a finding verified by a pletho
ra of studies. If you have the money,
you can buy the books and take the
ridiculously expensive courses de
signed to improve your scores —
I'm sure many Stanford students
themselves took advantage of such
services. Furthermore, the registra
tion costs for the SAT and the GRE
are $41.50 and $130, respectively
(absurd!). These tests measure the
size of your wallet more than they
measure your preparedness for any
sort of schooling.
As one professor explained to
me, these tests have not proven to be
significant indicators of academic
performance. However, Stanford,
along with most other universities,
still requires them. Why are they
perpetuating racist language
norms? Why does Stanford make us
take an exam that teaches us to
think within the box. but then tell us
to think outside of it on the first day
ofIHUM?
Maybe we need some way of as
sessing students that isn't available
from standard college applications,
but these high-priced jokes adminis
tered by ETS are not the answer. Ei
ther we need better tests or we need
a better application process, but we
need to encourage Stanford and
other universities to stop wasting
our time and our money on tests that
aren't worth the paper they're print
ed on.

This week's column was written hv
Bharat. He and Vinni write this col
umn, sometimes together, sometimes
separately. You can contact them at
bvenkat@stanford.edu and/or
vpi@stanford.edu.
