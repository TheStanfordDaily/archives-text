# Opinions
## Stu's Views The Insanity of the U.S. News Rankings
### 
August has been a summer of
circuses. We first had the cir
cus of the Olympics. Then we
have the circus of the Democratic
National Convention, a glorified
extended commercial that the media
pretends actually matters. But at
least those two happen once every
four years. The higher-education
community has to endure annual
unveilings of the controversial U.S.
News & World Report rankings of
undergraduate universities. Who
went down? Who went up? Which
schools "goosed" the rankings? Like
it or not, admissions offices nation
wide must hang on every decimal
point, as they know an improved
ranking can drive thousands more
applicants to their school. Just wit
ness the boon to Penn's acceptance
rate after the school cracked the top
five.
It is indeed a shame that these
rankings matter. Besides the obvious
conflict-of-interest (the conflicting
priorities of higher education and a
magazine trying to sell as many issues
as possible), the U.S. News & World
Report methodology is grossly
Hawed. Instead of measuring out
comes, the report focuses on incom
ing statistics — SAT ranges, incom
ing students in the top 10 percent of
their high school class and so on.
"Freshman retention" weighs heavi
ly, so schools that have difficult first
year programs like Caltech and MIT
suffer.
The magazine also uses "alumni
giving rate" as part of its methodolo
gy; it is unclear how an alum from the
Class of 1980 writing a $ 1 (X) check
has anything to do with the quality of
the school in 2008. So although
Stanford tends to raise twice as much
money annually as Princeton, they
trail in that category due to the high
er number of alumni at Princeton
who donate. Indeed, the rankings
have not been kind to the Farm.
Stanford has trailed behind Harvard,
Yale and Princeton for the past
decade — mostly because of the
lower admissions standards for ath
letes, in my opinion.
Rankings have become quite an
industry. The undergraduate rank
ings issue is U.S. News's top-selling.
Forbes, Newsweek and other publi
cations have created their own rank
ings to capitalize on the rankings
bonanza as undergraduate admis
sions become ever-more competitive.
Forbes' attempt was particularly
weak; a full 25 percent of the
methodology was based on rate
myprofessors.com. The use of that
site creates debilitating selection bias
issues that should — although they
won't — de-legitimize Forbes' rank
ings entirely. I do not know a single
person who has ever used that Web

site. U.S. News, for its part, does not
make its "Common Data Set," which
all universities submit, publicly avail
able, hindering transparency.
Most critics of the U.S. News
rankings argue that it is impossible to
rank schools at all. I disagree. A few
years ago, the Wall Street Journal did
a study of professional school place
ment. They ranked undergraduate
institutions by how many students (as
a percentage of their class) got into
top professional schools. While pro
fessional-school placement is only
one measure of educational out
come, it is decidedly an important
one and shows which universities
professional schools prefer. But very
little data of that sort is publicly avail
able. More studies that measure
placement and outcome would rank
schools far more accurately than the
dreamt-up, always-changing method
ology of U.S. News.
"Cross-admits" remain the holy
grail of undergraduate admissions
statistics, and the data most useful to
those attempting to rank schools.
For the past several years,
Princeton was top-ranked despite
academic studies showing that stu
dents admitted to both Harvard
and Princeton would choose
Harvard 70 percent of the time.
Sorting students by where they
actually choose to go to school,
rather than where some profit
seeking magazine thinks they
should go is the most meaningful
way to rank colleges. Importantly,
it prevents colleges from manipu
lating statistics to move up the
rankings. Any incentives that col
leges can use to increase their cross
admit yield, like better financial-aid
offers and merit-scholarship pro
grams, will only benefit students.
Instead, the U.S. News rankings set
up a perverse system where schools
like Washington University in St.
Louis will waitlist thousands of
good students in order to lower
their acceptance rate.
It has reached a point where the
rankings have a pernicious effect on
the behavior of schools themselves.
Instead of moving to a more trans
parent, nonbinding early action
program, or even better, eliminat
ing early admissions entirely, the
rankings incentivize schools to hold
onto their early decision programs
and use the waitlist as much as pos
sible. There is even speculation that
Stanford's proposal to increase its

class size by 200 students is moti
vated by Princeton's recent class
size increase, as well as Yale and
Chicago's plans to do so.
Competition and transparency
are good for college admissions.
We are, unfortunately, working
under a system that does not allow

the efficiencies of the market to
work. A lack of access to informa
tion that really matters, not "alum
ni giving rate" and "faculty
resources" hinders the ability to
rank colleges effectively and most
importantly, for high-school stu
dents to make the right decision

about their educational future

Stuart Baimel thinks that the preseason
college football rankings are as distorted
ftv the U.S. News rankings. Oklahoma
cuid German are ranked five places too
high every year. Serul him your pick for
Most Overrated to shaimel@stanford.edu.



McCAIN TEXTINS U& VCE FREF?ICENTIAL PICK
