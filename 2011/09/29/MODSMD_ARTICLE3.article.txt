# Profs brief Congress on teacher evaluations
## Darling-Hammond, Haertel discuss flaws in VAM system 
### JENNY THAI DESK EDITOR 
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
At a Sept. 14 Capitol Hill briefing, School of Educa
tion professors Linda Darling-Hammond and Edward
H. Haertel, among other leading education re
searchers, presented their findings on a central concern
in federal and state policy how teacher perform
ance should be evaluated.
One popular type of teacher evaluation is the value
added method (VAM) system, which uses statistical
methods to measure gains in student achievement. The
VAM system measures changes in student test scores
over time, while taking into account other factors that
are found to influence achievement.
According to Haertel, who also serves as chair of

the National Research Council Board on Testing and
Assessment, one major flaw of the VAM system is that
it gives policymakers the illusion of a "quick fix" for im
proving student performance by identifying teachers'
level of competency through their VAM scores.
"There's a hope that [problems will be solved] by
funding poor teachers that need to either be given
some remedial assistance or discouraged from contin
uing to teach," Haertel said. "I've not been surprised
that these models have been caught on and have been
so popular among policymakers."
Surprisingly, the problem with the VAM system is
not with its reliance of standardized testing scores, he
continued.


Stanford Daily File Photo
School of Education professor Linda Darling-Hammond delivered the keynote address at a 2008 forum on
education. She and prof. Edward Haertel briefed Capitol Hill on measuring teacher performance Sept. 14.
"It's not the tests, per se," Haertel
said. "It's easy to say we need better
tests, but that has been tried again
and again. The tests we have are pret
ty good at what they do."
Because the VAM system does
not account for factors such as the
amount of teacher infrastructural
support, class sizes and individual stu
dent learning needs, an important
side-effect of the system is an in
crease in competition between teach
ers to perform well. This side effect
may result in teacher neglect of the
population of students who may
need the most help, such as low-in
come students from non-English
speaking backgrounds.
"We create incentives with these
value-added systems with teachers
who try to avoid students who might
do poorly on the tests or students
who might not make rapid gains in
the test scores," Haertel said.
The VAM system's measurement
of teacher effectiveness has proven
unstable and unreliable. One study
showed that out of teachers who
scored in the bottom 20 percent of
rankings in one year, only 20 to 30
percent had similar ratings the next
year. These results suggest that
teacher evaluations should focus
more on measuring and expanding
professional development.
"We need both professional de
velopment and accountability, and
right now, the equation is out of bal
ance," Haertel said. "We have much
more focus on accountability and
much less on giving teachers the re
sources they need to develop skills
and do a better job of accomplishing
their work."
Darling-Hammond proposed al
ternatives to the VAM system, calling
for performance-based assessments
and standards-based evaluations.
This alternative system will combine

evaluations on different fronts in dif
ferent mediums into a portfolio that
reliably tracks the teacher's growth in
his or her teaching craft.
"It's a pretty big job to assemble
that evidence, which has to be scored
by trained evaluators to produce a re
liable score," Darling-Hammond
said. "That kind of evaluation can be
done at certain key junctures, such as
when you first enter the teaching pro
fession, during tenure-based deci
sions, at evaluations where teachers
can become mentor teachers ... it is
a very time-consuming and rigorous
process."
Despite the cost of implementing
a more stringent teacher evaluation
system, Darling-Hammond is opti
mistic that policymakers will be more
enthusiastic about seeking teacher
evaluation assessments that are more
reflective of teacher effectiveness.
"There's an appetite in investing
[in] teacher evaluation," Darling-
Hammond said. "These value-added
models are themselves quite costly,
though they don't actually end up
being very reliable, stable or valid."
"If you want to improve teaching,
making investments in these pro
grams that provide solid evaluation
and more teacher assistance, it will
probably prove to be less expensive
and more productive," she added.

Contact Jenny Thai at jthail@stan
ford.eclu.

Its a pretty big
job to assemble
the evidence
LINDA DARLING
HAMMOND,
education professor
