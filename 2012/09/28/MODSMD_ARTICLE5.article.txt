# ACADEMICS
## Fix sought for course evals 
### SHELLEY XU 
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
A committee has been appoint
ed to revise the course evaluation
process and will aim to submit a
proposal for altering course evalu
ations in the spring of 2013.

The committee comes as a
response to the Study of
Undergraduate Education at
Stanford report, which read,
"despite some improvements, the

[course] evaluation process still
leaves much to be desired."
For spring quarter 2012, 61.7
percent of instructors and 5.8 per
cent of students viewed the results
of course evaluations. The num
bers are even worse when com
pared to previous quarters; 76.5
percent of faculty and 14 percent
of students viewed course evalua
tion results in fall 2010.
However, senior associate reg

istrar Sharon Velten said that stu
dents' response rate is still very
high. Students completed approxi
mately 80 percent of the 54,000
possible course evaluations and
45,000 possible section evalua
tions.

"It does seem as though stu
dents are not answering the open
ended comments as much as they
used to," Assistant Vice Provost
for Undergraduate Education
Michele Marincovich said.
Stanford is currently pursuing
a partnership with Class Owl, a
student-run company, to provide
the results of course evaluations in
a more user-friendly format.
Class Owl will be able to display
internal University data that web
sites such as Courseßank do not
have access to.
"You're going to be getting 100
percent of the data," Class Owl
Operations and Marketing Director
Julienne Lam 'l3 said. "It helps [stu
dents] weed out information."
Velten said that the registrar's
office thinks it is very important
for students to be able to see the
course evaluation information in a
way that will make reading and
understanding the data easiest for
the student.
"If we provide more accurate
representations of what's actually
going on in the classes, how people
feel about the content, the direc
tion of the course, the overall
grade of the course, how they eval
uate their professors, then stu
dents will have more incentive to
put in time and effort," Lam said.
"The way they are structured is
not very compelling to be accurate
because students are submitting
them at the end of the quarter and
so they ... no longer care about
the class."
The last major change in the
course evaluation system was
seven years ago, when the
University transferred course
evaluation administration from a
paper form to the current online
version

"I think the important thing is
that students should realize that
teaching evaluations are taken
very seriously and are an impor
tant part of big decisions like
granting tenure or promotion,"
Marincovich said.
Course evaluations are consid
ered alongside letters from under
graduate students, graduate stu
dents and postdoctoral fellows
that either took a class from or
were supervised by the professor,
according to Provost John
Etchemendy.
"When a faculty member
comes up for reappointment or
tenure, the department collects
together a substantial amount of
evidence about the quality of their
classroom teaching and mentoring
of graduate students,"
Etchemendy wrote in an email to
The Daily.
But Etchemendy acknowl
edged the limitations of the course
evaluations system.
"Obviously, if everyone loves
the course but also rates it as
extremely easy, the people reading
the promotion file take that into
account," he said.
Economics Department chair
Jon Levin echoed Etchemendy's
concern that evaluations are not
100 percent dependable, saying
that small classes such as
Introductory Seminars will often
have higher course evaluations
than large lecture classes.
Others find the reports down
right harmful. English
Department chair Gavin Jones
said that his department found the
University course evaluations to
be, on the whole, inadequate and,
sometimes, thoughtless and hurt
ful to faculty.
"We developed a new course
evaluation," Jones said. "We really
felt in our department that the
standard course evaluation was

not detailed enough and did not
necessarily map itself onto the
learning goals that we have in
English, so we generated our own
evaluations to get into the
mechanics of how our course was
being taught."
However, Jones said that his
department often finds useful
comments in student course eval
uations.
"Particularly the qualitative
comments can really help me see
some weak points in a course and
realize a glitch here or there,"
Jones said.
Chemistry Department chair
W.B. Moerner said that his depart
ment frequently takes student
comments from course evalua
tions into account.

"Sometimes students say, 'We
would like more practice prob
lems,' so we prepare more practice
problems with solutions."
Russell Berman, a professor of
comparative literature and
German studies, will chair the
course evaluation committee.
"I hope the committee will
develop a form that can meet two
goals: provide better feedback to
instructors on how students are
learning in their classes, while also
providing students with an oppor
tunity to engage in thoughtful
reflection on their own learning
experience," Berman wrote in an
email to The Daily.

Contact Shelley Xu at sxuB@stan
ford.edu.
